\label{chap:metodologia}

La aplicación de las series cronológicas tiene por objetivos: 1) el análisis exploratorio de la serie en cuestión, 2) estimar modelos de proyección, y 3) generar pronósticos para los posibles valores futuros que tomará la serie cronológica.

Tomando en consideración dichos aspectos, esta sección aborda la metodología propuesta como método de estimación y pronóstico de series cronológicas. En la búsqueda de una ecuación de estimación adecuada de entre varias candidatas, se cubren en un primer apartado los materiales a utilizar, así como los métodos, incluyendo el proceso de estimación, el procedimiento de simulación empleado para la verificación del método propuesto, y las medidas de bondad de ajuste y de precisión a utilizar. 

```{r}
# Se describe en detalle a lo largo de este apartado el uso de la sobreparametrización como herramienta para la generación de pronósticos de series cronológicas con temporalidades mensuales, bimensuales, trimestrales, cuatrimestrales o anuales mediante un proceso de selección fundamentada en las permutaciones de todos los parámetros de un modelo ARIMA hasta un rango determinado.
# 
# Finalmente, las medidas de precisión y de bondad de ajuste sirven de insumo para utilizar un método de consenso entre ellas y seleccionar el modelo más adecuado mediante la sobreparametrización: se comparan todos los posibles modelos en un intervalo específico de términos definiendo una diferenciación adecuada para la serie y permutando hasta un máximo definido para los términos autorregresivos y de medias móviles especificados para así seleccionar la especificación que ofrezca mejores resultados al momento de pronosticar valores futuros de la serie cronológica.
```

\subsection{Materiales}

Se describen a continuación las series cronológicas reales que servirán de insumo para poner a prueba el método propuesto.

\subsubsection{Tasa de mortalidad infantil interanual}

La Tasa de Mortalidad Infantil (TMI) es uno de los indicadores demográficos más importantes, pues es utilizado como un parámetro de referencia sobre la calidad del sistema de salud, tanto a nivel nacional como regional. Si bien este indicador se construye relacionando las defunciones de menores de un año con el total de nacimientos, también involucra de manera implícita otras condiciones tales como las económicas, las sociales y las culturales, así como la efectividad en los métodos preventivos y curativos de esta categoría poblacional [@leon]. Debido a esto, el fallecimiento de un niño menor de un año se traduce en una falla del sistema de salud, por lo que estos casos son sujetos de estudio por parte de las autoridades con el fin de conocer las causas que desencadenaron el evento. 

En algunos países en vías de desarrollo de Asia, África y América Latina, la mortalidad infantil alcanza valores elevados pues la desnutrición, la ausencia de asistencia médica y la mala calidad de las condiciones sanitarias son, a diferencia de los países más desarrollados, algo muy común [@donoso]. En el caso de Costa Rica, la unidad de estadísticas demográficas del Instituto Nacional de Estadística y Censos[^6] (INEC) es el ente encargado de reportar este indicador con el fin de dar seguimiento y control al comportamiento de este a lo largo del tiempo con el objetivo de llegar a los niveles más bajos posibles. 

[^6]: http://www.inec.go.cr/

El INEC cada mes publica el boletín de la TMI interanual (TMII), que analiza la TMI de un mes y los 11 meses previos para comparar los periodos correspondientes [@infantiles]. Este apartado busca hacer un análisis de la TMII para los 12 periodos desde el año 1989 y hasta 2017, y no de manera mensual simple, pues dada la volatilidad del fenómeno de estudio, hacer un estudio interanual permite analizar de una mejor manera los cambios entre periodos. Esta forma de definir la TMII genera una autocorrelación natural en los datos, pues la información utilizada en el momento $t$ coincide en alrededor de 92% con la TMII del mes periodo inmediatamente anterior. Se analizará entonces la TMII desde el periodo febrero 1989 – enero 1990 hasta el periodo enero 2017 – diciembre 2017.

La importancia de este proceso, aparte de servir de parámetro para evaluar el sistema de salud, está en su estrecha relación con las proyecciones de población, pues como se mencionó previamente, la TMII analiza la mortalidad en el grupo de edad de menores de un año, que es el primer grupo al generar tablas de mortalidad, ya sea de la forma clásica o mediante la mortalidad óptima [@mortalidad_optima]. Uno de los métodos más conocidos para realizar estas estimaciones es el método de los componentes de cambio demográfico, que son la fecundidad, la mortalidad y la migración. En el caso de la mortalidad, uno de los puntos de partida es la estimación de las tasas de mortalidad por grupos de edad, siendo de particular interés la de menores de cinco años, pues esta a su vez se subdivide en los grupos de menores de un año y el de uno a cuatro años. Conocer el comportamiento de la mortalidad infantil es importante porque es en este grupo de edad en el que pueden existir cambios muy bruscos en la mortalidad y la fecundidad [@Rincon].



\subsubsection{Mortalidad por causa externa}

La violencia es un acto tan antiguo como el mundo, sin embargo, la evolución de esta en conjunto con el crecimiento de su relación con las defunciones registradas en una población la vuelven un problema de salud pública. Con base en la clasificación Internacional de Enfermedades [@CIE10] de la de la Organización Mundial de la Salud[^7], las defunciones pueden clasificarse en cuatro grandes grupos, las causas naturales son la causa más importante, ya que son enfermedades congénitas, cardiopatías u otras relacionadas con la vejez. En menor cuantía se encuentran las causas de muerte ignoradas, las cuales se dan cuando la causa de muerte es desconocida y de intención indeterminada; y de forma similar se encuentran las causas de muerte que se mantienen en estudio, bien sea por parte de la morgue o de algún otro organismo, esta causa de muerte tiene pocos registros conforme más se retrocede en el tiempo.
  
El otro gran grupo, aunque considerablemente menor que las causas naturales, son las causas externas, las cuales son objeto de análisis en este apartado. Este grupo puede a su vez ser clasificado en homicidios, suicidios y las muertes accidentales, esta última comprende los accidentes de tránsito, las muertes por caídas, personas ahogadas, víctimas de incendios, terraplenes u otros similares. Aunado a estas categorías se encuentran también las causas indeterminadas, que se diferencian de las ignoradas en que se sabe que se debe a una causa externa pero no se conoce con certeza a cuál categoría pertenece o aún está en investigación, tal es el caso de una persona que fallece debido a una alta ingesta de drogas o estupefacientes; bien pudo haber consumido intencionalmente hasta morir, como sería un suicidio, o bien el consumo excesivo se debió a un accidente.

En Costa Rica para el año 2011, las muertes por causas externas ocuparon el tercer lugar, solo superadas por las enfermedades del sistema circulatorio, en particular las enfermedades cardiovasculares, y por tumores, ambos casos mostraron una tendencia ascendente [@nacion]. 

A raíz de los elevados costos económicos y sociales [@ccpexternas] se aborda la imperiosa necesidad comprender el comportamiento de las defunciones debido a las causas externas con el fin de contar con un punto de partida para la elaboración de políticas públicas que busquen reducir al mínimo este tipo de eventos.

[^7]: https://www.paho.org/salud-en-las-americas-2017/?lang=es]

\subsubsection{Incentivos salariales del sector público}

Los incentivos salariales son retribuciones que de conformidad con la legislación vigente se asignan al servidor por sus características laborales que complementan las remuneraciones básicas. Los incentivos se reconocen tanto a profesionales como a no profesionales, facultados por disposiciones jurídicas que así lo autorizan. Algunos de estos incentivos son: anualidades, dedicación exclusiva, salario escolar, carrera profesional, carrera técnica, zonaje, desarraigo, regionalización, riesgo policial, riesgo penitenciario, riesgo de seguridad y vigilancia, peligrosidad, incentivo didáctico, entre otros. La serie cronológica de incentivos salariales se representa mediante millones de colones del sector público de Costa Rica de enero 2007 a junio 2015; este es un periodo suficientemente extenso para los objetivos de este estudio, por lo que obtener datos más recientes no generaría un aporte sustantivo a esta investigación.

\subsubsection{Intereses y comisiones del sector público}

Finalmente, se utiliza para este análisis la serie cronológica de los intereses y comisiones del sector público. Estas comprenden el pago de los intereses de la deuda del gobierno, es decir, las erogaciones de intereses y comisiones destinadas por las instituciones públicas para cubrir el pago a favor de terceras personas, físicas o jurídicas, del sector privado o del sector público, residentes en el territorio nacional o en el exterior, por la utilización en un determinado plazo de recursos financieros provenientes de los conceptos de emisión y colocación de títulos valores, contratación de préstamos directos, créditos de proveedores, depósitos a plazo y a la vista, intereses por deudas de avales asumidos, entre otros pasivos de la entidad tranzados en el país o en el exterior. Además, incluye el pago por concepto de otras obligaciones contraídas entre las partes, que no provienen de las actividades normales de financiamiento. Igualmente abarca los intereses y comisiones por las operaciones normales de los bancos comerciales del sector público, así como las diferencias por tipo de cambio por operaciones financieras; y también el pago de intereses moratorios correspondientes a la deuda pública. 

\subsubsection{Herramientas analíticas}

Como se ha mencionado en este documento, el lenguaje de programación R ha sido utilizado para los análisis. Específicamente, los paquetes utilizados para la obtención de estos resultados, aparte de los ya mencionados, son `knitr` [@knitr], `kableExtra` [@kableExtra], `readxl` [@readxl], `gridExtra` [@gridExtra], `ggpubr` [@ggpubr], `ggplot2` [@ggplot2], `lubridate` [@lubridate], `ggseas` [@ggseas], `ggpmisc` [@ggpmisc] y `forecast` [@forecast].

\subsubsection{Procedimiento de simulación}

Como parte de esta investigación, es necesario validar la identificación de los parámetros de los modelos ARIMA mediante sobreparametrización no solo con datos reales, sino también mediante datos simulados. Para ello, es necesario generar series cronológicas que son gobernadas por un proceso determinado y previamente conocido para poder compararlo con los modelos identificados tanto con la sobreparametrización, como con la función `auto.arima()` y el correspondiente modelo $ARIMA$ estándar. 

Con este fin, se programó una función que sigue los siguientes pasos (también mostrados en la Figura \ref{fig:diagrama_flujo_simulacion}:

```{r}
## **1.** Se generan valores aleatorios de alguna distribución de probabilidad. Para esta investigación se escogen 100 valores de una distribución Normal con media 10 y varianza 1. Estos valores se resumen en la Figura \ref{fig:datos_simulados}; donde las región azul oscuro representa la densidad de datos entre los percentiles 25 y 75, las líneas punteadas de color naranja marcan la cantidad de desviaciones estándar que los datos se alejan del promedio, y las líneas punteadas de color azul marcan los puntos de corte mínimo, percentiles 25, 50 y 75, y el máximo.
```

**1.** Se selecciona mediante un muestreo simple al azar la cantidad de coeficientes a utilizar en los términos del modelo $ARIMA(p,d,q)(P,D,Q)_S$ que gobierna la serie. Para esta investigación fueron seleccionados los siguientes procesos: $ARIMA(1,0,0), ARIMA(1,0,1),$ $ARIMA(2,0,3), ARIMA(4,0,2),$ $ARIMA(0,0,1)(0,1,1)_{12}$ y $ARIMA(2,1,4)(3,0,3)_{12}$.

**2.** Para cada uno de los procesos seleccionados, se generan valores aleatorios de una distribución uniforme con un valor mínimo de 0 y un valor máximo de 0.99. La cantidad de valores simulados depende de la cantidad de parámetros escogidos en $p, q, P, Q$. Estos valores aleatorios son transformados de manera tal que los polinomios de la parte autorregresiva y de medias móviles no compartan raíces unitarias, este es un proceso iterativo que se completa hasta que los coeficientes obtenidos tanto para la parte autorregresiva como para la parte de medias móviles generen un proceso invertible y estacionario.

```{r, eval=FALSE}
# https://arxiv.org/pdf/1611.01387.pdf
# https://github.com/cran/arfima/blob/master/R/InvertibleQ.R
# https://github.com/cran/arfima/blob/master/R/ARToPacf.R
```

**3.** Con la cantidad de parámetros y sus respectivos valores definidos en los puntos anteriores, se ajusta cada uno de los modelos $ARIMA$ descritos en el inciso **1.**.

**4.** Con cada modelo ajustado, se utiliza la función `simulate.Arima()` para generar 200 observaciones basadas en dichos modelos.

```{r diagrama_flujo_simulacion, fig.cap="Diagrama de flijo del proceso de simulación de las series cronológicas \\textcolor{white}{prueba de aaaaaaaaaaaaaaaaaaaaaaa}"}
#https://graphviz.org/docs/attrs/splines/
#https://stackoverflow.com/questions/7115870/creating-straight-edges-in-graphviz/12869546
grViz(diagram = 'digraph start_up {

    { 

        node [shape=rect label="Descartar combinación\nde coeficientes"]; descartar; 
    }

    {   
        node [width=0 shape=point label=""];
         descartar;
    }

    node [style = rounded]; 
    node [shape = rect label="Seleccionar cantidad\nde coeficientes"] coef;
    node [style = ""];
    
    node [shape = rect label="Simular coeficientes"] coef_sim;
    node [style = ""];
    
    node [shape = diamond label="¿El proceso es invertible y\nestacionario?"] invert;
    node [style = ""];
    
    node [shape = rect label="Estimar ARIMA"] estimar_arima;
    node [style = ""];
    
    node [style = rounded]; 
    node [shape = rect label="Simular serie"] simular_serie;
    node [style = ""];
    
    coef -> coef_sim;
    
    coef_sim->invert;
    
    {rank=same; descartar -> coef_sim;}
    
    invert -> descartar [label = "No" tailport=w headport=s];
    
    invert -> estimar_arima [label = "Sí"];
    
    estimar_arima -> simular_serie;

}')

```
\text{Fuente: elaboración propia}

```{r, echo=FALSE, results='hide', cache=TRUE}
# load(popstudy::read_from_dir("Resultados simulaciones.RData", "Output/Results"))
load(popstudy::read_from_dir("Resultados_2022.RData", "Output/Results"))
```
```{r}
#Aquí corrijo los modelos arima estandar de las simulaciones, porque cuando lo hice (ver línea207 de "Borrador de resultados.Rmd") puse data, cuando era train.

# for(i in 1:2){
#     comparacion_no_estacional_bajo[[i]]$modelos$arima_estandar <- Arima(comparacion_no_estacional_bajo[[i]]$modelos$autoarima$x, order = c(1,1,1),method="ML")
#     
#     comparacion_no_estacional_alto[[i]]$modelos$arima_estandar <- Arima(comparacion_no_estacional_alto[[i]]$modelos$autoarima$x, order = c(1,1,1),method="ML")
#     
#     comparacion_estacional_bajo[[i]]$modelos$arima_estandar <- Arima(comparacion_estacional_bajo[[i]]$modelos$autoarima$x, order = c(1,1,1), seasonal = list(order=c(1,1,1)),method="ML")
#     
#     comparacion_estacional_alto[[i]]$modelos$arima_estandar <- Arima(comparacion_estacional_alto[[i]]$modelos$autoarima$x, order = c(1,1,1), seasonal = list(order=c(1,1,1)),method="ML")
# }
```

```{r datos_simulados, fig.cap="Valores de referencia para la simulación de series cronológicas \\textcolor{white}{prueba de aaaaaaaaaaaaaaaaaaaaaaa}", eval=FALSE}
popstudy::descriptive_plot(data = data.frame(Xt=dat), Xt, labels = "Datos simulados", ylab = "Densidad")[[1]]
```

\subsection{Métodos}

En este apartado se describe el procedimiento a seguir con cada una de las series cronológicas mencionadas previamente, tanto las series simuladas como las reales. Para comprobar el poder predictivo del método propuesto se realiza inicialmente un análisis exploratorio para verificar si las series temporales sujetas a análisis son o no estacionarias y, en caso de no serlo, si requieren algún proceso de diferenciación. Se describe además el proceso de partición de los datos tanto para ajustar los modelos como para validar los pronósticos.

\subsubsection{Análisis exploratorio}

Como fue mencionado en el Marco Teórico, debe corroborarse que la serie cronológica a trabajar posea un comportamiento estacionario y, de no serlo, someterla a transformaciones para asegurar esta condición, estando entre los más comunes la diferenciación o la aplicación del logaritmo natural. Posteriormente, se realiza una identificación del posible proceso que gobierna la serie cronológica al graficar las funciones de autocorrelación y autocorrelación parcial, las cuales también sirven para verificar si la serie (transformada o no) es estacionaria.

\subsubsection{Partición de los datos}

A partir de la serie cronológica que se someterá a análisis, se realiza una partición de los datos para tener dos conjuntos distintos: entrenamiento y validación. El primero servirá precisamente para entrenar y estimar los distintos modelos, mientras que el segundo servirá para validar los pronósticos obtenidos. De manera predeterminada, se utilizará una partición del 80% de los datos para el conjunto de entrenamiento y un 20% para los datos de validación, pues es la proporción más tradicional, sin embargo, esto puede cambiar de acuerdo con el interés propio del o la investigadora, seleccionando una proporción distinta para las particiones. 

\subsubsection{Identificación y estimación del mejor modelo según la función auto.arima()}

Con el correspondiente conjunto de datos de entrenamiento, se utiliza la función `auto.arima()` para encontrar el mejor modelo ARIMA sugerido con este método, que, como fue mencionado en la introducción de esta tesis, usa como criterio la minimización del AICc y realiza la estimación mediante máxima verosimilitud.

\subsubsection{Identificación y estimación del mejor modelo con sobreparametrización}

A partir del mismo conjunto de datos de entrenamiento de la correspondiente serie cronológica, se utiliza la sobreparametrización para encontrar el mejor modelo a partir de distintas permutaciones de la cantidad de coeficientes de los términos $p, d, q, P, D, Q$, según sea el caso. 

La estimación mediante máxima verosimilitud de los modelos y posterior selección de estos vía sobreparametrización es un proceso que requiere de distintas etapas. El procedimiento completo fue programado utilizando el lenguaje R, el cual fue construido haciendo uso de los paquetes de R `tidyr` [@tidyr], `dplyr`[@dplyr] y `parallel`[@parallel], los procesos internos de esta función son descritos a continuación:

**1.** Una vez que se define la partición que tendrá la serie cronológica, se prosigue con la selección de los escenarios para estimar los modelos de ARIMA. Es en esta instancia en donde se decide el valor máximo de los parámetros $p,d,q,P,D,Q$ del modelo $ARIMA(p,d,q)(P,D,Q)_s$ que serán sujetos al análisis. 

**2.** Para el caso de series cronológicas no estacionales, los valores $P,D$ y $Q$ son iguales a cero porque precisamente, no se estiman coeficientes para la parte estacional. 

En el caso de la presente investigación, se estiman todas las permutaciones de parámetros $p,d,q$ hasta tener como máximo un modelo $ARIMA(6,1,6)$, aunque el orden del modelo más grande puede permitir un mayor número de diferenciaciones o de parámetros. Para ello se genera una matriz con cada una de estas permutaciones, denominada matriz de valores paramétricos, en donde cada fila representa la especificación del modelo $ARIMA(p,d,q)$ que se va a estimar, tal y como se muestra en \eqref{eqn:matriz_arima_1}:

```{r, eval=FALSE, echo=FALSE}
# Las siguiente matriz se obtuvo de:
# https://tex.stackexchange.com/questions/40/how-do-i-label-different-rows-or-columns-of-a-matrix-using-braces
# 
# 
# https://otexts.com/fpp2/classical-decomposition.html
```


\begin{equation}
\label{eqn:matriz_arima_1}
\begin{tikzpicture}[mymatrixenv]
    \matrix[mymatrix] (m)  {
        0 & 0 & 1 & 0 & 0 & 0 \\
        0 & 0 & 2 & 0 & 0 & 0 \\
        0 & 0 & 3 & 0 & 0 & 0 \\
        0 & 0 & 4 & 0 & 0 & 0 \\
        0 & 0 & 5 & 0 & 0 & 0 \\
        0 & 0 & 6 & 0 & 0 & 0 \\
        0 & 1 & 0 & 0 & 0 & 0 \\
        0 & 1 & 1 & 0 & 0 & 0 \\
        0 & 1 & 2 & 0 & 0 & 0 \\
        \vdots & \vdots & \vdots & \vdots & \vdots & \vdots \\
        6 & 1 & 6 & 0 & 0 & 0 \\
    };
    \mymatrixbracetop{1}{3}{$p, d, q$};
    \mymatrixbracetop{4}{6}{$P,D,Q$}
\end{tikzpicture}
\end{equation}

**3.** De manera análoga, al trabajar con series cronológicas estacionales, se decide trabajar (para una temporalidad determinada, como mensual) hasta un modelo máximo de $ARIMA(4,1,4)(4,1,4)_{12}$. De este modo, la matriz de valores paramétricos mostrada en \eqref{eqn:matriz_arima_2} posee, en cada línea, una especificación de modelo a estimar:

\begin{equation}
\label{eqn:matriz_arima_2}
\begin{tikzpicture}[mymatrixenv]
    \matrix[mymatrix] (m)  {
        0 & 0 & 1 & 0 & 0 & 1 \\
        0 & 0 & 1 & 0 & 0 & 2 \\
        0 & 0 & 1 & 0 & 0 & 3 \\
        0 & 0 & 1 & 0 & 0 & 4 \\
        0 & 0 & 1 & 0 & 1 & 1 \\
        0 & 0 & 1 & 0 & 1 & 2 \\
        0 & 0 & 1 & 0 & 1 & 3 \\
        \vdots & \vdots & \vdots & \vdots & \vdots & \vdots \\
        4 & 1 & 4 & 4 & 1 & 4 \\
    };
    \mymatrixbracetop{1}{3}{$p, d, q$};
    \mymatrixbracetop{4}{6}{$P,D,Q$}
\end{tikzpicture}
\end{equation}

**4.** Debido a que los modelos a estimar cuentan con varias cantidades de parámetros en la parte no estacional y en la parte estacional, resulta pertinente generar una medida de referencia para conocer el nivel de sobreparametrización de los modelos en el espacio de valores paramétricos definido. 

A partir de las estimaciones vía sobreparametrización hechas para este estudio, se calcularon los tiempos de estimación para modelos no estacionales y modelos estacionales. Estos tiempos se muestran en el Cuadro \ref{tab:tiempos_estimacion}. 

Para calcular el indicador de sobreparametrización $(I_{sp})$, primero se calcula el tiempo mediano de estimación, tanto para los modelos no estacionales como para los modelos estacionales. Para este estudio se obtuvo que el tiempo mediano para los modelos no estacionales fue de aproximadamente $7.424944$ minutos, mientras que para los modelos estacionales el tiempo mediano de estimación fue de $36.0432$ minutos, aproximadamente.

Luego, a cada fila de la matriz de valores paramétricos se le calcula un promedio ponderado a la cantidad de coeficientes en la parte no estacional y en la parte estacional, utilizando como ponderador los tiempos de estimación descritos previamente. Este procedimiento se expresa en la ecuación \eqref{eqn:indicador_sp},

\begin{equation}
\label{eqn:indicador_sp}
I_{sp} = \frac{(p+q) \cdot m_n + (P+Q) \cdot m_e}{2\cdot(m_n+m_e)}
\end{equation}

donde $p,q,P$ y $Q$ son los términos del modelo ARIMA, $m_n$ es el tiempo mediano expresado en minutos para modelos no estacionales, y $m_e$ es el tiempo mediano expresado también en minutos para modelos estacionales. De esta manera, el valor de $I_{sp}$ para un $ARIMA(3,1,1)(2,0,1)_S$ estaría dado por $\frac{(3+1) \cdot 7.424944 + (2+1) \cdot 36.0432}{2\cdot(7.424944+36.0432)} \approx 1.58540673$.

Por último, el valor de $I_{sp}$ es reescalado de forma tal que sus valores estén en el intervalo $[0,100]$ para el espacio de valores paramétricos definido, donde el cero representa el modelo nulo y 100 el modelo más sobreparametrizado posible dentro del espacio de valores paramétricos definido. La razón de esto es poder limitar, si se desea, la cantidad de estimaciones que se deben realizar. Por ejemplo, si se define que la matriz de valores paramétricos llegue como máximo a un $ARIMA(6,1,6)(6,1,6)_S$, es posible incorporar una restricción para estimar solo aquellas permutaciones de modelos $ARIMA$ cuyo indicador de sobreparametrización sea menor o igual a 60. 

**5.** Con la matriz de valores paramétricos, como las mostradas en \eqref{eqn:matriz_arima_1} y \eqref{eqn:matriz_arima_2} y el indicador de sobreparametrización, se inicia la estimación los modelos en orden ascendente, es decir, del modelo con menos parámetros al que tiene más parámetros. Al estimar un nuevo modelo, se evalúa mediante una prueba *t* [@astsa] para verificar que el nuevo término incorporado al modelo es significativamente distinto de cero, es decir; el nuevo parámetro está generando un impacto en el modelo.

**6.** Al tratarse de un proceso iterativo, el cálculo puede volverse computacionalmente pesado, es por esta razón que la programación del proceso fue habilitada para realizar procesamiento paralelo y de esta manera reducir el consumo de tiempo en la obtención de resultados.

**7.** Cuando se han realizado las pruebas de significancia estadística a los modelos, son calculadas las medidas de bondad de ajuste y de rendimiento que se mencionarán más adelante. 

**8.** Tras esto, se aplica un método de consenso para seleccionar el modelo más adecuado. Este criterio consiste en darle una mayor o menor ponderación a los resultados obtenidos con el conjunto de datos de entrenamiento y el de validación. De forma predeterminada se le da una ponderación de 0.8 a los resultados de validación y un 0.2 a los de entrenamiento, porque en la práctica, los datos de validación son considerados como datos más recientes y que, mientras más cercanos sean los pronósticos a estos datos, mejores resultados ofrece el modelo seleccionado. El método de consenso es utilizado para obtener un puntaje de cada modelo ARIMA, su cálculo se obtiene de la ecuación \eqref{eqn:concenso}:

\begin{equation}
\label{eqn:concenso}
min\left( \sum_i {m_i}\cdot w_j \right)
\end{equation}

Donde $m_i$ representa cada una de las medidas de rendimiento y $w_j$ es el valor de ponderación de los conjunto de entrenamiento y validación mencionados anteriormente. El valor más bajo de todos los modelos es el que se define como el modelo más adecuado.

\subsubsection{Estimación de un modelo ARIMA estándar}

Para contrastar los dos métodos de selección de modelos anteriores (`auto.arima()` y sobreparametrización), se ajusta también un modelo ARIMA más tradicional o estándar. En el caso de las series cronológicas no estacionales se ajusta un modelo $ARIMA(1,1,1)$ y en el caso de las series estacionales se ajusta un modelo $ARIMA(1,1,1),(1,1,1)_S$.

\subsubsection{Análisis visual de los errores}

Una vez que se selecciona un modelo de cada tipo (`auto.arima()`, sobreparametrización y ARIMA estándar), se realiza un análisis visual de los residuos estandarizados, la autocorrelación y el supuesto de normalidad de los residuales un histograma de los residuos.

\subsubsection{Medidas de bondad de ajuste y de rendimiento}

El objetivo último al estimar un modelo ARIMA es obtener los pronósticos de dicho modelo. Sin embargo, estos pronósticos no pueden asumirse como correctos, sino que se debe evaluar su calidad con las llamadas medidas de bondad de ajuste y de precisión, aplicadas a los conjuntos de entrenamiento y validación. Existen múltiples medidas, @medidas menciona, entre otras, las siguientes: 

\paragraph{AIC}

Se calcula de la siguiente manera: 

\begin{equation}
\label{eqn:AIC}
AIC=-2logL\left(\hat\theta\right)+2k
\end{equation}

Donde $k$ es el número de parámetros y $n$ el número de datos.

\paragraph{AICc}

Su forma de cálculo se muestra en la ecuación \eqref{eqn:AICc}
\begin{equation}
\label{eqn:AICc}
AICc=-2logL\left(\hat\theta\right)+2k+\frac{2k+1}{n-k-1}
\end{equation}

Donde $k$ es el número de parámetros y $n$ el número de datos.

\paragraph{BIC}

El último estadístico de bondad de ajuste se calcula como se muestran en la ecuación \eqref{eqn:BIC}.

\begin{equation}
\label{eqn:BIC}
BIC=-2logL\left(\hat\theta\right)+k\cdot log(n)
\end{equation}

Donde $k$ es el número de parámetros y $n$ el número de datos.

\paragraph{MAE}

El error absoluto medio se define mediante la ecuación \eqref{eqn:MAE}

\begin{equation}
\label{eqn:MAE}
\frac{1}{n}\sum_{t=1}^n |e_t|
\end{equation}

\paragraph{MASE}

Esta medida de rendimiento tiene dos casos; uno para series cronológicas no estacionales y otro para series cronológicas estacionales, como se muestra en las ecuaciones \eqref{eqn:MASE_no} y \eqref{eqn:MASE_si}.

\begin{equation}
\label{eqn:MASE_no}
\frac{\frac{1}{J}\sum_j|e_j|}{\frac{1}{T-1}\sum_{t=2}^T|Y_t-Y_{t-1}|}
\end{equation}

\begin{equation}
\label{eqn:MASE_si}
\frac{\frac{1}{J}\sum_j|e_j|}{\frac{1}{T-m}\sum_{t=m+1}^T|Y_t-Y_{t-m}|}
\end{equation}

Donde $m$ es la temporalidad de la serie.

\paragraph{RMSE}

Es la raíz del error cuadrático medio, como se define en la ecuación \eqref{eqn:RMSE}.

\begin{equation}
\label{eqn:RMSE}
\sqrt{\frac{1}{n}\sum_{t=1}^n |e_t^2|}
\end{equation}

\subsubsection{Pronósticos}

Para cada modelo estimado, se realiza un pronóstico de $h$ periodos hacia el futuro (donde el valor de $h$ es el tamaño de los conjuntos de validación creados para cada serie) para realizar una inspección visual de los resultados previo a hacer una comparación numérica mediante dos formas distintas pero complementarias; las medidas de bondad de ajuste y de precisión.

\subsubsection{Tiempo de procesamiento}

Para cada uno de los modelos estimados mediante sobreparametrización, se mostrará el tiempo de procesamiento requerido en cada serie cronológica, esto con el fin de evaluar la viabilidad del método propuesto para la obtención de resultados. Esta etapa de importante porque independientemente de los resultados obtenidos con la sobreparametrización, el tiempo de procesamiento debe mantenerse dentro de un margen razonable para quienes apliquen la técnica, ya que, si se tardaran varios días en obtener los cálculos, sería un procedimiento poco práctico.

\subsubsection{Resumen de la forma de análisis}

De esta manera, cada una de las series cronológicas (simuladas y reales) serán sometidas a un análisis exploratorio en donde se analizará más en detalle el comportamiento de cada una. Posteriormente, a partir de la serie completa que sea sujeta a análisis, se ejecuta una partición de los datos con un 80% para el conjunto de entrenamiento y el restante 20% para validación, esto con el fin de obtener la mejor ecuación de estimación sugerida por cada una de las tres técnicas.

Una vez que se complete esta etapa, se completará una inspección visual del comportamiento de los errores con el fin de verificar que se cumplan las condiciones descritas en el Marco Teórico de esta investigación para posteriormente calcular las medidas de bondad de ajuste y de precisión para tanto para el periodo de entrenamiento como el de validación.Finalmente, se cierra el análisis de las series cronológicas simuladas y reales con una comparación de los valores predichos con respecto al conjunto de validación, esto con el fin de contrastar la calidad de los resultados.
