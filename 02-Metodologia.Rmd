\section{REFERENTES O ELEMENTOS TEÓRICOS QUE VA A UTILIZAR} 

\subsection{Modelos Arima}

Los modelos ARIMA, junto con los de suavizamiento exponencial, son los de uso más extendido en el análisis de series cronológicas. El nombre ARIMA es la abreviatura inglesa  para *AutoRegresive Integrated Moving Average*, y son aplicados mediante la metodología de Box-Jenkins. Como menciona Rob. Hyndman [@hyndman_box-jenkins], la metodología de Box-Jenkins difiere a los demás métodos porque no supone un determinado patrón en la serie cronológica, si no que parte de un proceso iterativo para identificar el modelo de un gran grupo de estos para luego ponerlo a prueba según varias medidas de rendimiento. Un proceso ARIMA es caracterizado por dos funciones: la autocorrelación y la autocorrelación parcial; el enfoque Box-Jenkins compara estas funciones con el objetivo de identificar el proceso que describa de manera adecuada el comportamiento de una serie cronológica [@oscarh-3].

El componente **AR** de los modelos ARIMA hace referencia al uso de modelos autorregresivos, en los cuales los pronósticos para la variable de interés utilizan una combinación lineal de las observaciones previas, llamándose así *autorregresivos* porque se aplica una regresión de dicha variable de interés con respecto a sí misma; caso contrario a la regresión múltiple, en donde los pronósticos se realizan con respecto a una combinación lineal de distintos predictores. Un modelo autorregresivo de orden $p$ para una serie cronológica $y_t$ puede expresarse de la siguiente manera

\begin{equation}
y_t=c+\phi_1y_{t-1}+\phi_2y_{t-2}+\cdots+\phi_py_{t-p}+\epsilon_t
\end{equation}

Donde el término $\epsilon_t$ representa ruido blanco. El modelo anterior es muy similar a una regresión lineal múltiple, donde cada coeficiente $\phi$ va acompañado por su correspondiente rezago $y_{t-p}$. De manera muy similar, el término **MA** en los modelos ARIMA se refieren a los modelos de medias móviles, los cuales para pronosticar hacen uso de los errores; el modelo de medias móviles puede representarse de la siguiente manera:

\begin{equation}
y_t=c+\epsilon_t+\theta_1\epsilon_{t-1}+\theta_2\epsilon_{t-2}+\cdots+\theta_q\epsilon_{t-q}
\end{equation}

Donde el término $\epsilon_t$ representa nuevamente el ruido blanco. La ecuación anterior representa un modelo de medias móviles de orden $q$, en la cual cada término $\epsilon_{t-q}$ se entiende como una media móvil de los $t$ previos errores de predicción.

El componente **I** de los modelos ARIMA se refiere a “Itegrated”, es decir, a la estacionariedad de la serie cronológica. Tradicionalmente, la metodología de Box-Jenkins consiste en visualizar la serie cronológica con el objetivo de, en caso de ser necesario, transformar los datos para estabilizar la variancia y generar así un proceso estacionario. Se dice que una serie posee un comportamiento estacionario si el comportamiento de esta no depende del tiempo, por lo que en principio no presentaría ningún patrón particular con respecto al tiempo; en otras palabras, la serie posee un movimiento bastante horizontal. 

Cuando la serie cronológica muestre indicios de tendencia o patrones estacionales que resulten en un conjunto de datos que no es estacionario por naturaleza, es necesario realizar transformaciones sobre los datos para hacer que la serie se vuelva estacionaria [@diferenciacion]. Estas transformaciones hacen referencia al uso de logaritmos o alguna potencia que logre estabilizar la variabilidad de la serie. Los métodos más clásicos para identificar la no estacionariedad en una serie cronológica son las previamente mencionadas funciones de autocorrelación y autocorrelación parcial, las cuales sirven de indicador acerca de qué tan relacionadas están las observaciones unas de otras. Estas funciones ofrecen indicios sobre el orden de los términos previamente mencionados **AR** y **MA**.

\subsection{Función de autocorrelación}

Para medir la relación lineal entre dos variables cuantitativas, es común utilizar el coeficiente de correlación $r$ de Pearson [@pearson], el cual se define para dos variables $X$ e $Y$ como sigue:

\begin{equation}
r_{X,Y}=\frac{E(XY)}{\sigma_X \sigma_Y} = \frac{\sum_{i=1}^n \left(X_i- \bar X\right) \left(Y_i- \bar Y\right)}{\sqrt{\sum_{i=1}^n \left(X_i- \bar X\right)^2 \sum_{i=1}^n \left(Y_i- \bar Y\right)^2}}
\end{equation}

Este mismo concepto puede aplicarse a las series cronológicas para comparar el valor de la misma en el tiempo $t$, con su valor en el tiempo $t-1$, es decir, se comparan las observaciones consecutivas $Y_t$ con $Y_{t-1}$. Esto también es aplicable a no solo una observación rezagada $(Y_{t-1})$, sino también con múltiples rezagos $(Y_{t-2}), (Y_{t-3}), \cdots,(Y_{t-n})$. Para esto se hace uso del coeficiente de autocorrelación.

El coeficiente de autocorrelación recibe su nombre debido a que se utiliza el coeficiente de correlación para pares de observaciones $r_{Y_t, Y_{t-1}}$ de la serie cronológica. Al conjunto de todas las autocorrelaciones se le llama función de autocorrelación.

\subsection{Función de autocorrelación parcial}

La función de autocorrelación parcial busca medir la asociación lineal entre las observaciones $Y_t$ y $Y_{t-k}$, descartando los efectos de los rezagos $1,2, \cdots ,k-1$[@oscarh-4]


\subsection{Modelos ARIMA no estacionales}

Como se mencionó anteriormente, los modelos ARIMA aplicados a una serie cronológica $Y_t$ son una combinación de un modelo autorregresivo, uno de medias móviles, y alguna clase de diferenciación (logarítmica, exponenciación) para así obtener una serie diferenciada $Y’_t$. Si se juntan ambas se obtiene un modelo ARIMA(p,d,q) que no cubre los efectos estacionales, donde $p$ es el orden del modelo autorregresivo, $d$ e el grado de la diferenciación y $q$ es el orden del modelo de medias móviles; y cuya estructura se muestra en la ecuación (4):

\begin{equation}
y'_t=c+\phi_1y'_{t-1}+\phi_2y'_{t-2}+\cdots+\phi_py'_{t-p}+\theta_1\epsilon_{t-1}+\theta_2\epsilon_{t-2}+\cdots+\theta_q\epsilon_{t-q} +\epsilon_t
\end{equation}

\subsection{Modelos ARIMA estacionales}

Los modelos ARIMA son también capaces de cubrir los efectos estacionales, es decir, particularidades de la serie cronológica que se repiten periódicamente con una cierta temporalidad (mensual, bimensual, etc.). Para ello se incorporan términos adicionales al modelo relacionados con la parte estacional de una manera similar a como se incorporan en el modelo ARIMA no estacional, pero ahora considerando retrocesos según sea la temporalidad estacional, pasando así de un $ARIMA(p,d,q)$ a un $ARIMA(p,d,q)(P,D,Q)_S$, donde $P$, $D$ y $Q$ se refieren a la parte estacional y $S$ a la temporalidad presente en la serie. 

\subsection{Medidas de rendimiento}

Cuando se tiene el modelo ARIMA estimado, es importante realizar los pronósticos. Sin embargo, estos pronósticos no son imperativos, sino que se debe evaluar su calidad con las llamadas medidas de rendimiento. Estas mediciones son hechas comparando el pronóstico y su diferencia con el valor real. Existen múltiples medidas de rendimiento, Adhikari [@medidas] menciona las siguientes: 

\subsubsection{MAE}

El error absoluto medio se define como $\frac{1}{n}\sum_{t=1}^n |e_t|$. 

\subsubsection{MAPE}

El porcentaje promedio de error absoluto se define como $\frac{1}{n}\sum_{t=1}^n \left|\frac{e_t}{y_t}\right|\cdot 100$.

\subsubsection{RMSE}

Es la raíz del error cuadrático medio $\sqrt{\frac{1}{n}\sum_{t=1}^n |e_t^2|}$.

\subsubsection{MASE}

Para series no estacionales: $\frac{\frac{1}{J}\sum_j|e_j|}{\frac{1}{T-1}\sum_{t=2}^T|Y_t-Y_{t-1}|}$

Para series estacionales: $\frac{\frac{1}{J}\sum_j|e_j|}{\frac{1}{T-m}\sum_{t=m+1}^T|Y_t-Y_{t-m}|}$

Donde $m$ es la temporalidad de la serie.

\subsubsection{AIC}

Se calcula de la siguiente manera: $AIC=-2logL\left(\hat\theta\right)+2k$. 
Donde $k$ es el número de parámetros y $n$ el número de datos.

\subsubsection{AICc}

Se calcula de la siguiente manera: $AICc=-2logL\left(\hat\theta\right)+2k+\frac{2k+1}{n-k-1}$.
Donde $k$ es el número de parámetros y $n$ el número de datos.

\subsubsection{BIC}

Se calcula de la siguiente manera: $BIC=-2logL\left(\hat\theta\right)+k\cdot log(n)$.

Donde $k$ es el número de parámetros y $n$ el número de datos.

